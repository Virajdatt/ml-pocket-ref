{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c4ea87d",
   "metadata": {},
   "source": [
    "## Chapter 3 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa00793",
   "metadata": {},
   "source": [
    "## Leaky features\n",
    "\n",
    "Leakage is also termed Data Leakage\n",
    "\n",
    "Leaky features are variables that contain information about the future or target. There’s nothing bad in having data about the target, and we often have that data during model creation time. However, if those variables are not available when we perform a prediction on a new sample, we should remove them from the model as they are leaking data from the future.\n",
    "\n",
    "<b>Leakage (machine learning)<b>\n",
    "\n",
    "In statistics and machine learning, leakage (also known as data leakage or target leakage) is the use of information in the model training process which would not be expected to be available at prediction time, causing the predictive scores (metrics) to overestimate the model's utility when run in a production environment.\n",
    "\n",
    "\n",
    "<b>Data Leakage Examples</b>\n",
    "\n",
    "1. Giveaway features: Giveaway features are the features that expose information about the target variable and would not be available after the model is deployed.\n",
    "\n",
    "2. Leakage during preprocessing: If preprocessing is done on both train and test set.\n",
    "\n",
    "<b>How to Detect and Avoid Data Leakage</b>\n",
    "\n",
    "As a general, if the model is too good to be true, we should get suspicious. The model might be somehow memorizing the feature-target relations instead of learning and generalizing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c58a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68257db7",
   "metadata": {},
   "source": [
    "[Data Science Project Suggestion](!https://drivendata.github.io/cookiecutter-data-science/)\n",
    "\n",
    "### Classification Problem Flow\n",
    "\n",
    "1. Gather Data\n",
    "2. Clean Data\n",
    "3. Create Features\n",
    "4. Sample Data (split train and test data)\n",
    "5. Impute Data\n",
    "6. Normalize Data / (Refactor code)\n",
    "7. Baseline Model\n",
    "8. Build Classifier\n",
    "9. Stack\n",
    "10. Evaluate Model\n",
    "11. Optimize Model (Hyper-parameter tuning)\n",
    "12. Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee12e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee5cb45c",
   "metadata": {},
   "source": [
    "## Chapter 4 Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3979f9f6",
   "metadata": {},
   "source": [
    "To visualize patterns in the missing data, use the missingno library. This library is useful for viewing contiguous areas of missing data, which would indicate that the missing data is not random (see Figure 4-1). The matrix function includes a sparkline along the right side. Patterns here would also indicate non‐ random missing data. You may need to limit the number of samples to be able to see the patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccca69c",
   "metadata": {},
   "source": [
    "A <b>dendrogram</b> can also show missing data it is done by clustering of where data is missing ). Leaves that are at the same level predict one another’s presence (empty or filled). The vertical arms are used to indicate how different clusters are. Short arms mean that branches are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ab513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1854f9d6",
   "metadata": {},
   "source": [
    "## Chapter 5 Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8748d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c891d290",
   "metadata": {},
   "source": [
    "## Important note on pandas behaviour\n",
    "\n",
    "Up to pandas 0.23, if the type is int64, we are guaranteed that there are no missing values. If the type is float64, the values might be all floats, but also could be integer-like numbers with missing values. The pandas library converts integer values that have missing numbers to floats, as this type supports missing values. The object typically means string types (or both string and numeric).\n",
    "\n",
    "\n",
    "As of pandas 0.24, there is a new Int64 type (notice the capitalization). This is not the default integer type, but you can coerce to this type and have support for missing numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ff036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3adf2ac3",
   "metadata": {},
   "source": [
    "## Chapter 6 Exploring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94215b36",
   "metadata": {},
   "source": [
    "A pandas DataFrame has an iloc attribute that we can do index operations on. It will let us pick out rows and columns by index location. We pass in the row positions as a scalar, list, or slice, and then we can add a comma and pass in the column positions as a scalar, list, or slice.\n",
    "Here we pull out the second and fifth row, and the last three columns:\n",
    "<code> X.iloc[[1, 4], -3:] ;sex_male embarked_Q embarked_S\n",
    "    677       1.0           0           1\n",
    "    864       0.0           0           1\n",
    "    \n",
    "</code>\n",
    "There is also a .loc attribute, and we can put out rows and columns based on name (rather than position). Here is the same portion of the DataFrame:\n",
    "<code> X.loc[[677, 864], \"sex_male\":] ;sex_male embarked_Q embarked_S 677 1.0 0 1 864 0.0 0 1\n",
    "\n",
    "</code>\n",
    "\n",
    "\n",
    "###  Joint Plot\n",
    "Yellowbrick has a fancier scatter plot that includes histograms on the edge as well as a regression line called a joint plot\n",
    "\n",
    "### Pair Grid\n",
    "Using seaborn\n",
    "\n",
    "Kernel Density Estimations:\n",
    "- https://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/AV0405/MISHRA/kde.html\n",
    "- https://www.youtube.com/watch?v=x5zLaWT5KPs\n",
    "\n",
    "### Pandas chaining sample\n",
    "\n",
    "\n",
    "### Correlation/Covarince correlation graph (yellowbrick and seaborn)\n",
    "\n",
    "### Heatmap\n",
    "\n",
    "### RadViz (yellowbricks/Pandas as implements RadViz Plot)\n",
    "\n",
    "A RadViz plot shows each sample on a circle, with the features on the circumference. The values are normalized, and you can imagine that each figure has a spring that pulls samples to it based on the value.\n",
    "This is one technique to visualize separability between the targets.\n",
    "\n",
    "\n",
    "\n",
    "### Parallel Coordiantes (yellowbricks/Pandas as implements RadViz Plot)\n",
    "\n",
    "For multivariate data, you can use a parallel coordinates plot to see clustering visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea68849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbfde298",
   "metadata": {},
   "source": [
    "## Chapter 7 Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f0a4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd078626e5cb14307b2371f3946c1caa5bbc168a9eda33df78f60dc6faeb16eeee6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
